#+TITLE: Notes on: Computer architecture: a quantitative approach by Hennessy, J. L. (2019)
#+Time-stamp: <2021-05-26 11:01:47 boxx>

- source :: cite:hennessy-2019-comput

* TODO Summary

* TODO Comments

* TODO Topics

** RISC-Based Machines

Advancements in technology / costs/ etc made it possible to develop successfully a new set of architectures with simpler instructions, called RISC (Reduced Instruction Set Computer) architectures in the early 1980s. The RISC-based machines focused the attention of designers on two (2) critical performance techniques:

  1. the exploitation of /instruction-level parallelism/ (initially through pipelining and later through multiple instruction issue)
  2. the use of caches (initially in simple forms and later using more sophisticated organizations and optimizations)

The RISC-based computers raised the preformance bar, forcing prior architecture to keep up or disappear. The Digital Equipment Vax could not, and so it was replaced by a RISC architecture. Intel rose to the challenge, primarily by translating 80x86 instructions into RISC-like instructions internally, allowing it to adopt many of the innovations first pioneered in the RISC designs. As transistor counts soared in the late 1990s, the hardware overhead of translating the more complex x86 architecture became negligible. In low-end applications, such as cell phones, the cost in power and silicon area of the x86-translation overhead helped lead to a RISC architecture, ARM, becoming dominant.

** Classes of Parallelism and Parallel Architectures

Parallelism at multiple levels is now the driving force of computer design across all four classes of computers, with energy and cost being the primary constraints. There are basically two (2) kinds of parallelism in applications:

  1. /Data-level parallelism (DLP)/ arises because there are many data items that can be operated on at the same time.
  2. /Task-level parallelism (TLP)/ arises because tasks of work are created that can operate independently and largely in parallel.

Computer hardware in turn can exploit these two (2) kinds of application parallelism in four (4) major ways:

  1. /Instruction-level parallelism/ exploits data-level parallelism at modest levels with compiler help using ideas like pipelining and at medium levels using ideas like speculative execution.
  2. /Vector architectures, graphic processor units (GPUs), and multimedia instruction sets/ exploit data-level parallelism by applying a single instruction to a collection of data in parallel.
  3. /Thread-level parallelism/ exploits either data-level parallelism or task-level parallelism in a tightly coupled hardware model that allows for interaction between parallel threads.
  4. /Request-level parallelism/ exploits parallelism among largely decoupled tasks specified by the programmer or the operating system.

When Flynn (1966) studied the parallel computing efforts in the 1960s, he found a simple classification whose abbreviations we still use today. They target data-level parallelism and task-level parallelism. He looked at the parallelism in the instruction and data streams called for by the instructions at the most constrained component of the multiprocessor and placed all computers in one of four (4) categories:

  1. /Single instruction stream, single data stream/ (SISD) - This category is the uniprocessor. The programmer thinks of it as the standard sequential computer, but it can exploit ILP. Chapter 3 covers SISD architectures that use ILP techniques such as superscalar and speculative execution.
  2. /Single instruction stream, multiple data streams/ (SIMD) - The same instruction is executed by multiple processors using different data streams. SIMD computers exploit /data-level parallelism/ by applying the same operations to multiple items of data in parallel. Each processor has its own data memory (hence, the MD of SIMD), but there is a single instruction memory and control processor, which fetches and dispatches instructions. Chapter 4 covers DLP and three (3) different architectures that exploit it: vector architectures, multimedia extensions to standard instruction sets, and GPUs.
  3. /Multiple instruction streams, single data stream/ (MISD) - No commercial multiprocessor of this type has been built to date, but it rounds out this simple classification.
  4. /Multiple instruction streams, multiple data streams/ (MIMD) - Each processor fetches its own instructions and operates on its own data, and it targets task-level parallelism. In general, MIMD is more flexible than SIMD and thus more generally applicable, but it is inherently more expensive than SIMD. For example, MIMD computers can also exploit data-level parallelism, although the overhead is likely to be higher than would be seen in an SIMD computer. This overhead means that grain size must be sufficiently large to exploit parallelism efficiently. Chapter 5 covers tightly coupled MIMD architectures, which exploit /thread-level parallelism/ because multiple cooperating threads operate in parallel. Chapter 6 covers loosely coupled MIMD architectures - specifically, /clusters/ and /warehouse-scale computers/ - that exploit /request-level parallelism/, where many independent tasks can proceed in parallel naturally with little need for communication or synchronization.

This taxonomy is a coarse model, as many parallel processors are hybrids of the SIS, SIMD, and MIMD classes. Nonetheless, it is useful to put a framework on the design space for computers we will see in this book.

** Defining Computer Architecture

The task the computer designer faces is a complex one: determine what attributes are important for a new computer, then design a computer to maximize performance and energy efficiency while staying within cost, power, and availability constraints. This task has many aspects, including instruction set design, functional organization, logic design, and implementation. The implementation may encompass integrated circuit design, packaging, pwer, and cooling.

A few decades ago, the term /computer architecture/ generally referred to only instruction set design. Other aspects of computer design were called /implementation/, often insinuating that implementation is uninteresting or less challenging. *We believe this view is incorrect*. The architect's or designer's job is much more than instruction set design, and the technical hurdles in the other aspects of the project are likely more challenging than those encountered in instruction set design.

*** Instruction Set Architecture: The Myopic View of Computer Architecture

We use the term /instruction set architecture/ (ISA) to refer to the actual programmer-visible instruction set in this book. *The ISA serves as the boundary between the software and hardware*. This quick review of ISA will use examples from 80x86, ARMv8, and RISC-V to illustrate the seven (7) dimensions of an ISA.

RISC-V is a modern RISC instruction set developed at the University of California, Berkeley, which was made free and openly adoptable in response to requests from industry. In addition to a full software stack (compilers, operating systems, and simulators), there are several RISC-V implementations freely available for use in custom chips or in field-programmable gate arrays. Developed 30 years after the first RISC instruction sets, RISC-V inherits its ancestors' good ideas - a large set of registers, easy-to-pipeline instructions, and a lean set of operations - while avoiding their omissions or mistakes. It is a free and open, elegant example of the RISC architectures mentioned earlier, which is why more than 60 companies have joined the RISC-V foundation. We use the integer core ISA of RISC-V as the example ISA in this book.

1. /Classes of ISA/ - Nearly all ISAs today are classified as general-purpose register architectures, where the operands are either registers or memory locations. The 80x86 has 16 general-purpose registers and 16 that can hold floating-point data, while RISC-V has 32 general-purpose and 32 floating-point registers. The two (2) popular versions of this class are /register-memory/ ISAs, such as the 80x86, which can access memory as part of many instructions, and /load-store/ ISAs, such as ARMv8 and RISC-V, which can access memory _only_ with load or store instructions. All ISAs announced since 1985 are load-store.
2. /Memory addressing/ - Virtually all desktop and server computers, including the 80x86, ARMv8, and RISC-V, use byte addressing to access memory operands. Some architectures, like ARMv8, require that objects must be /aligned/. An Access to an object of size /s/ bytes at byte /A/ is aligned if /A/ mod /s/ = 0. The 80x86 and RISC-V do *not* require alignment, but accesses are generally faster if operands are aligned.
3. /Addressing modes/ - In addition to specifying registers and constant operands, addressing modes specify the address of a memory object. RISC-V addressing modes are Register, Immediate (for constants), and Displacement, where a constant offset is added to a register to form the memory address. The 80x86 supports those three modes, plus three variations of displacement: no register (absolute), two registers (based indexed with displacement), and two registers where one register is multiplied by the size of the operand in bytes (based on scaled index and displacement). It has more like the last three modes, minus the displacement field, plus register indirect, indexed, and based with scaled index. ARMv8 has the three RISC-V addressing modes plus PC-relative addressing, the sum of two registers, and the sum of two registers where one register is multiplied by the size of the operand in bytes. It also has autoincrement and autodecrement addressing, where the calculated address replaces the contents of one of the registers used in forming the address.
4. /Types and sizes of operands/ - Like most ISAs, 80x86, ARMv8, and RISC-V support operand sizes of 8-bit (ASCII character), 16-bit (Unicode character or half word), 32-bit (integer or word), 64-bit (double word or long integer), and IEE 754 floating point in 32-bit (single precision) and 64-bit (double precision). The 80x86 also supports 80-bit floating point (extended double precision).
5. /Operations/ - The general categories of operations are data transfer, arithmetic, logical, control, and floating point. RISC-V is a simple and easy-to-pipeline instruction set architecture, and it is representative of the RISC architectures being used in 2017. The 80x86 has a much richer and larger set of operations.
6. /Control flow instructions/ - Virtually all ISAs, including these three, support conditional branches, unconditional jumps, procedure calls, and returns. All three use PC-relative addressing, where the branch address is specified by an address field that is added to the PC.
7. /Encoding an ISA/ - There are two (2) basic choices on encoding: /fixed length/ and /variable length/. *All ARMv8 and RISC-V instructions are 32 bits long, which simplifies instruction decoding*. The 80x86 encoding is variable length, ranging from 1 to 18 bytes. Variable-length instructions can take less space than fixed-length instructions, soa program compiled for the 80x86 is usually smaller than the same program compiled for RISC-V. /Note that choices mentioned previously will affect how the instructions are encoded into a binary representation/. For example, the number of registers and the number of addressing modes both have a significant impact on the size of instructions, because the register field and addressing mode field can appear many times in a single instruction. (Note that ARMv8 and RISC-V later offered extensions, called Thumb-2 and RV64IC, that provide a mix of 16-bit and 32-bit length instructions, respectively, to reduce program size. Code size for these compact versions of RISC architectures are smaller than that of the 80x86.)

   The other challenges facing the computer architect beyond ISA design are particularly acute at the present, when the difference among instruction sets are small and when there are distinct application areas. Therefore, starting with the fourth edition of this book, beyond this quick review, the bulk of the instruction set material is found in the appendices (see Appendices A and K).

*** Genuine Computer Architecture: Designing the Organization and Hardware to Meet Goals and Functional Requirements

The implementation of a computer has two (2) components: organization and hardware. The terms /organization/ includes the high-level aspects of a computer's design, such as the memory system, the memory interconnect, and the design of the internal processor or CPU (Central Processing Unit .... where arithmetic, logic, branching, and data transfer are implemented). The term /microarchitecture/ is also used instead of /organization/. For example, two (2) processors with the same instruction set architecture but different organizations are the AMD Opteron and the Intel Core i7. Both processors implement the 80x86 instruction set, but they have very different pipeline and cache organizations.

The switch to multiple processors per microprocessor led to the term /core/ also being used for processors. Instead of saying multiprocessor microprocessor, the term /multicore/ caught on. Given that virtually all chips have multiple processors, the term central processing unit, or CPU, is fading in popularity.

/Hardware/ refers to the specifics of a computer, including the detailed logic design and the packaging technology of the computer.  Often a line of computers contains computers with identical instruction set architectures and very similar organizations, but they differ in the detailed hardware implementation. For example, the Intel Core i7 and the Intel Xeon E7 are nearly identical but offer different clock rates and different memory systems, making the Xeon E7 more effective for server computers.

In this book, the word /architecture/ covers all three (3) aspects of computer design:

  1. instruction set architecture
  2. organization or microarchitecture
  3. hardware

To plan for the evolution of a computer, the designer must be aware of rapid changes in implementation technology. Five (5) implementation technologies, which change at a dramatic pace, are critical (!) to modern implementations:

  1. /Integrated circuit logic technology/ - Historically, transistor density increased by about 35% per year, quadrupling somewhat over four years. Increases in die size are less predictable and slower, ranging from 10% to 20% per year. The combined effect was a traditional growth rate in transistor count on a chip of about 40% to 55% per year, or doubling every 18-24 months. This trend is popularly known as Moore's Law. Device speed scales more slowly, as we discuss below. Shockingly (!), Moore's Law is no "moore" (!). The number of devices per chip is still increasing, but at a decelerating rate. Unlike in the Moore's Law era, we expect the doubling time to be stretched with each new technology generation.
  2.
